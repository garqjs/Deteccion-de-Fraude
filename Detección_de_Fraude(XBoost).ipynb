{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O0G1pR4-iJC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Montar Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# AJUSTA ESTA RUTA a donde descargues los archivos de IEEE-CIS\n",
        "base_path_fraud = '/content/drive/My Drive/Colab Notebooks/Detecci√≥n fraude/'\n",
        "\n",
        "train_trans = base_path_fraud + 'train_transaction.csv'\n",
        "train_id    = base_path_fraud + 'train_identity.csv'\n",
        "\n",
        "# Conexi√≥n DuckDB\n",
        "con = duckdb.connect(database=':memory:')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Limpieza de Tiempo y Montos\n",
        "# El tiempo viene en segundos. Sacaremos la hora y el d√≠a.\n",
        "query_trans = f\"\"\"\n",
        "CREATE OR REPLACE VIEW trans_clean AS\n",
        "SELECT\n",
        "    TransactionID,\n",
        "    isFraud,\n",
        "    TransactionAmt,\n",
        "    TransactionDT,\n",
        "    -- Ingenier√≠a de Tiempo: Ciclos de 24h y 7 d√≠as\n",
        "    CAST((TransactionDT / 3600) % 24 AS INT) AS hour_of_day,\n",
        "    CAST((TransactionDT / 86400) % 7 AS INT) AS day_of_week,\n",
        "    -- Variable de Negocio: ¬øEs un monto redondo? (Frecuente en lavado/fraude)\n",
        "    CASE WHEN TransactionAmt % 1 = 0 THEN 1 ELSE 0 END as is_round_amount,\n",
        "    card1, card2, card3,\n",
        "    P_emaildomain,\n",
        "    dist1\n",
        "FROM read_csv_auto('{train_trans}')\n",
        "\"\"\"\n",
        "\n",
        "# 2. Identidad: Dispositivo y Red\n",
        "query_identity = f\"\"\"\n",
        "CREATE OR REPLACE VIEW identity_clean AS\n",
        "SELECT\n",
        "    TransactionID,\n",
        "    DeviceType,\n",
        "    DeviceInfo,\n",
        "    -- Agrupamos dispositivos por marcas comunes para reducir cardinalidad\n",
        "    CASE\n",
        "        WHEN DeviceInfo LIKE '%Windows%' THEN 'Windows'\n",
        "        WHEN DeviceInfo LIKE '%iOS%' OR DeviceInfo LIKE '%iPhone%' THEN 'Apple'\n",
        "        WHEN DeviceInfo LIKE '%Android%' OR DeviceInfo LIKE '%Samsung%' THEN 'Android'\n",
        "        ELSE 'Other'\n",
        "    END as device_brand\n",
        "FROM read_csv_auto('{train_id}')\n",
        "\"\"\"\n",
        "\n",
        "# 3. Master Table: Uni√≥n (Aqu√≠ es donde ocurre la magia)\n",
        "query_master_fraud = \"\"\"\n",
        "SELECT\n",
        "    t.*,\n",
        "    i.DeviceType,\n",
        "    i.device_brand,\n",
        "    -- L√≥gica de Email: El dominio puede indicar riesgo\n",
        "    COALESCE(t.P_emaildomain, 'anonymous') as email\n",
        "FROM trans_clean t\n",
        "LEFT JOIN identity_clean i ON t.TransactionID = i.TransactionID\n",
        "\"\"\"\n",
        "\n",
        "# Ejecutar Pipeline de Fraude\n",
        "con.execute(query_trans)\n",
        "con.execute(query_identity)\n",
        "df_fraud = con.execute(query_master_fraud).df()\n",
        "\n",
        "print(f\"‚úÖ ¬°√âxito! Dataset consolidado ({df_fraud.shape[0]},{df_fraud.shape[1]})\")\n",
        "# Diagn√≥stico del dataset\n",
        "print(df_fraud.isnull().sum() / len(df_fraud)*100) # Porcentaje de nulos\n",
        "display(df_fraud.head())"
      ],
      "metadata": {
        "id": "cb0L_ETsHIyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fraud_audit(con, tables):\n",
        "    print(f\"{' AUDITOR√çA DE FRAUDE (IEEE-CIS) ':=^40}\")\n",
        "    for table in tables:\n",
        "        res = con.execute(f\"\"\"\n",
        "            SELECT\n",
        "                '{table}' as tabla,\n",
        "                COUNT(*) as total,\n",
        "                SUM(CASE WHEN TransactionID IS NULL THEN 1 ELSE 0 END) as nulos_id,\n",
        "                -- En fraude, nos interesa mucho el % de la clase positiva\n",
        "                AVG(CASE WHEN isFraud = 1 THEN 1.0 ELSE 0.0 END) * 100 as tasa_fraude\n",
        "            FROM {table}\n",
        "        \"\"\").df()\n",
        "        print(f\"üìä {res['tabla'][0]} | Total: {res['total'][0]} | Fraude: {res['tasa_fraude'][0]:.2f}%\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "# Ejecutar auditor√≠a\n",
        "# Nota: La tabla identity no tiene la columna isFraud, por eso solo auditamos la master\n",
        "run_fraud_audit(con, ['df_fraud'])"
      ],
      "metadata": {
        "id": "BY-7b_9IRNgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingenier√≠a de Variables: Velocity y Agregaciones\n",
        "query_velocity = f\"\"\"\n",
        "CREATE OR REPLACE VIEW features_velocity AS\n",
        "SELECT\n",
        "    TransactionID,\n",
        "    -- 1. Frecuencia: ¬øCu√°ntas transacciones ha hecho esta tarjeta (card1) en total?\n",
        "    COUNT(*) OVER(PARTITION BY card1) as card1_cnt,\n",
        "\n",
        "    -- 2. Desviaci√≥n del Monto: ¬øQu√© tanto var√≠a esta compra del promedio de la tarjeta?\n",
        "    TransactionAmt / AVG(TransactionAmt) OVER(PARTITION BY card1) as amt_to_mean_card1,\n",
        "\n",
        "    -- 3. Velocity Temporal: (Simulada con el orden de las transacciones)\n",
        "    -- En un dataset real usar√≠amos intervalos de tiempo, aqu√≠ usamos conteos acumulados\n",
        "    ROW_NUMBER() OVER(PARTITION BY card1 ORDER BY TransactionDT) as trans_count_total\n",
        "FROM trans_clean\n",
        "\"\"\"\n",
        "\n",
        "# Uni√≥n Final de Features\n",
        "query_final_model = \"\"\"\n",
        "SELECT\n",
        "    m.*,\n",
        "    v.card1_cnt,\n",
        "    v.amt_to_mean_card1,\n",
        "    v.trans_count_total\n",
        "FROM df_fraud m -- Aseg√∫rate que este nombre coincida con tu tabla anterior\n",
        "LEFT JOIN features_velocity v ON m.TransactionID = v.TransactionID\n",
        "\"\"\"\n",
        "\n",
        "# Ejecutamos en DuckDB\n",
        "con.execute(query_velocity)\n",
        "df_final = con.execute(query_final_model).df()\n",
        "\n",
        "print(f\"‚úÖ Dataset con Features de Velocity listo: {df_final.shape}\")"
      ],
      "metadata": {
        "id": "ZgteLGsMbrtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Calculamos la proporci√≥n de fraude por hora\n",
        "fraud_by_hour = df_fraud.groupby('hour_of_day')['isFraud'].mean()\n",
        "\n",
        "sns.lineplot(x=fraud_by_hour.index, y=fraud_by_hour.values, marker='o', color='red', linewidth=2.5)\n",
        "plt.fill_between(fraud_by_hour.index, fraud_by_hour.values, color='red', alpha=0.1)\n",
        "\n",
        "plt.title('Probabilidad de Fraude seg√∫n la Hora del D√≠a', fontsize=14)\n",
        "plt.xlabel('Hora (0-23)', fontsize=12)\n",
        "plt.ylabel('% Tasa de Fraude', fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.xticks(range(0, 24))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Smts6eiRzU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Filtramos para ver la distribuci√≥n de montos\n",
        "sns.kdeplot(df_fraud[df_fraud['isFraud'] == 0]['TransactionAmt'], label='Leg√≠tima', fill=True, color='blue', log_scale=True)\n",
        "sns.kdeplot(df_fraud[df_fraud['isFraud'] == 1]['TransactionAmt'], label='Fraude', fill=True, color='red', log_scale=True)\n",
        "\n",
        "plt.title('Distribuci√≥n de Montos: Leg√≠timo vs Fraude (Escala Log)', fontsize=14)\n",
        "plt.xlabel('Monto de Transacci√≥n (Log Scale)', fontsize=12)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqSkl-AESCCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un subplot de 1x2\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 1. Por Dispositivo\n",
        "sns.barplot(data=df_fraud, x='device_brand', y='isFraud', ax=ax[0], palette='viridis', ci=None)\n",
        "ax[0].set_title('Tasa de Fraude por Marca de Dispositivo')\n",
        "ax[0].set_ylabel('% Fraude')\n",
        "\n",
        "# 2. Por Dominio de Email\n",
        "# Tomamos solo los top 5 para que sea legible\n",
        "top_emails = df_fraud['email'].value_counts().nlargest(5).index\n",
        "df_top_emails = df_fraud[df_fraud['email'].isin(top_emails)]\n",
        "\n",
        "sns.barplot(data=df_top_emails, x='email', y='isFraud', ax=ax[1], palette='magma', ci=None)\n",
        "ax[1].set_title('Tasa de Fraude por Proveedor de Email')\n",
        "ax[1].set_ylabel('% Fraude')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-v-d1nLZSKoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Ordenar el DataFrame por tiempo\n",
        "df_final = df_final.sort_values('TransactionDT')\n",
        "\n",
        "# 2. Calcular el punto de corte (80%)\n",
        "split_idx = int(len(df_final) * 0.8)\n",
        "\n",
        "# 3. Dividir\n",
        "train_df = df_final.iloc[:split_idx]\n",
        "test_df  = df_final.iloc[split_idx:]\n",
        "\n",
        "print(f\"üìà Entrenamiento: {train_df.shape[0]} transacciones (Pasado)\")\n",
        "print(f\"üìâ Prueba: {test_df.shape[0]} transacciones (Futuro)\")"
      ],
      "metadata": {
        "id": "ibz1Lkzdyr_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir variables (Features)\n",
        "features = [\n",
        "    'TransactionAmt', 'hour_of_day', 'day_of_week', 'is_round_amount',\n",
        "    'card1', 'card2', 'dist1', 'card1_cnt', 'amt_to_mean_card1', 'trans_count_total'\n",
        "]\n",
        "\n",
        "# X e y para entrenamiento y prueba (usando el Time-Split anterior)\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['isFraud']\n",
        "\n",
        "X_test = test_df[features]\n",
        "y_test = test_df['isFraud']"
      ],
      "metadata": {
        "id": "hWAWHB5OziaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06e18b24"
      },
      "source": [
        "class FraudConfig:\n",
        "    XGB_PARAMS = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'aucpr',\n",
        "        'use_label_encoder': False, # Recomendado en versiones recientes de XGBoost\n",
        "        'n_estimators': 500,\n",
        "        'learning_rate': 0.05,\n",
        "        'max_depth': 5,\n",
        "        'subsample': 0.7,\n",
        "        'colsample_bytree': 0.7,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1 # Usar todos los cores disponibles\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "# --- MODELO A: XGBOOST EST√ÅNDAR ---\n",
        "model_a = xgb.XGBClassifier(**FraudConfig.XGB_PARAMS)\n",
        "model_a.fit(X_train, y_train)\n",
        "\n",
        "# --- MODELO B: XGBOOST BALANCEADO ---\n",
        "# Calculamos el ratio de desbalanceo: (Negativos / Positivos)\n",
        "ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "model_b = xgb.XGBClassifier(\n",
        "    **FraudConfig.XGB_PARAMS,\n",
        "    scale_pos_weight=ratio # Penaliza m√°s fuerte si falla en detectar un fraude\n",
        ")\n",
        "model_b.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "uvk6UGnc0qou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Usaremos el Modelo B por ser m√°s sensible al riesgo\n",
        "xgb.plot_importance(model_b, max_num_features=10, importance_type='gain',\n",
        "                   title='Top 10 Variables Predictoras de Fraude')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-qnFYxHB3CHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def plot_ks_gini(y_true, y_probs):\n",
        "    # 1. Preparar datos\n",
        "    df = pd.DataFrame({'target': y_true, 'proba': y_probs})\n",
        "    df = df.sort_values(by='proba', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # 2. Calcular acumulados\n",
        "    df['event'] = df['target'].cumsum() / df['target'].sum()\n",
        "    df['non_event'] = (1 - df['target']).cumsum() / (1 - df['target']).sum()\n",
        "    df['ks_diff'] = abs(df['event'] - df['non_event'])\n",
        "\n",
        "    # 3. M√©tricas\n",
        "    ks_stat = df['ks_diff'].max()\n",
        "    ks_idx = df['ks_diff'].idxmax()\n",
        "    ks_threshold = df.loc[ks_idx, 'proba']\n",
        "\n",
        "    auc = roc_auc_score(y_true, y_probs)\n",
        "    gini = 2 * auc - 1\n",
        "\n",
        "    # 4. Graficar\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(df['proba'], df['event'], label='Fraude Acumulado (Event)', color='red', lw=2)\n",
        "    plt.plot(df['proba'], df['non_event'], label='Leg√≠timo Acumulado (Non-event)', color='blue', lw=2)\n",
        "\n",
        "    # L√≠nea del KS\n",
        "    plt.axvline(ks_threshold, color='black', linestyle='--', alpha=0.7)\n",
        "    plt.text(ks_threshold, 0.5, f'  KS: {ks_stat:.2f}\\n  Threshold: {ks_threshold:.4f}',\n",
        "             fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.title(f'Curva de Separaci√≥n KS (Gini: {gini:.2f})', fontsize=14)\n",
        "    plt.xlabel('Umbral de Probabilidad (Score)', fontsize=12)\n",
        "    plt.ylabel('Distribuci√≥n Acumulada', fontsize=12)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.gca().invert_xaxis() # Invertimos para ver de mayor a menor probabilidad\n",
        "    plt.show()\n",
        "\n",
        "    return ks_stat, ks_threshold\n",
        "\n",
        "# Ejecutar con tus predicciones\n",
        "# Usamos el Modelo B (el que tiene scale_pos_weight)\n",
        "y_probs_b = model_b.predict_proba(X_test)[:, 1]\n",
        "ks_val, cut_off = plot_ks_gini(y_test, y_probs_b)"
      ],
      "metadata": {
        "id": "BatIe1jbDM-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Crear el explicador\n",
        "explainer = shap.TreeExplainer(model_b)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Resumen de variables\n",
        "plt.title(\"Impacto SHAP: ¬øQu√© variables empujan al Fraude?\")\n",
        "shap.summary_plot(shap_values, X_test)"
      ],
      "metadata": {
        "id": "Iqdx-c1ZD7NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 1. Calcular la matriz\n",
        "cm = confusion_matrix(y_test, y_pred_ks)\n",
        "\n",
        "# 2. Configurar el gr√°fico\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Leg√≠timo (0)', 'Fraude (1)'],\n",
        "            yticklabels=['Leg√≠timo (0)', 'Fraude (1)'])\n",
        "\n",
        "plt.title(f'Matriz de Confusi√≥n (Umbral KS: {threshold})', fontsize=14)\n",
        "plt.ylabel('Realidad', fontsize=12)\n",
        "plt.xlabel('Predicci√≥n del Modelo', fontsize=12)\n",
        "\n",
        "# A√±adir etiquetas explicativas\n",
        "plt.text(0.5, 0.2, 'Verdaderos Negativos\\n(Clientes Felices)', ha='center', va='center', color='white', fontweight='bold')\n",
        "plt.text(1.5, 0.2, 'Falsos Positivos\\n(Bloqueos Err√≥neos)', ha='center', va='center', color='black', fontweight='bold')\n",
        "plt.text(0.5, 1.2, 'Falsos Negativos\\n(Fraude Escapado)', ha='center', va='center', color='black', fontweight='bold')\n",
        "plt.text(1.5, 1.2, 'Verdaderos Positivos\\n(Fraude Atrapado)', ha='center', va='center', color='black', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_DHWePhI95P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}